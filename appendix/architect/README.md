

### 网站架构设计规划预案

> 系统架构师应根据之前的工作经验，设计合理的网站架构方案，编写核心模块的代码，引导技术团队树立正确的系统架构设计思想，指明正确的方向，规避以后网站升级可能会存在的风险。

#### 合理设计与规划

> 高流量高并发的网站一定要采用分布式的架构思想设计，可以采用DNS轮询将最外面的流量进行一级分流。一般来说，会采用如下设计：
- 重要的对外服务应尽量选用成熟的开源技术方案，并以Linux集群的方式对外提供服务，例如HAProxy/Nginx集群、Codis集群或ZooKeeper集群等。
- 合理地利用CDN系统，注意处理CDN回源的问题。
- 图片服务器采用独立的域名，而非二级域名。
- 核心系统尽量选用BGP机房或线路。
- 成本一定要控制，尽量选用免费开源方案。
- 尽量选用目前成熟稳定的开源技术。

#### 核心系统的开发设计

复杂的系统都不是通过单一代码完成的，其核心系统的开发和设计依赖于系统架构师和团队核心开发人员。系统架构师和团队核心开发人员都应具备核心代码与主要功能代码的编写能力和代码Review能力。

系统架构师要具备良好的沟通能力，能在产品、前端/后端、测试团队包括业务需求方之间自由穿插，能够将业务需求或产品需求转成技术需求，且有能力将复杂的任务分解。

慎重选用业务核心系统的开发框架，代码或核心系统重构在后期是一件非常复杂和痛苦的事情。


#### 规划好网站未来的发展

在设计网站系统架构之初，要评估当前系统的PV、UV、QPS/RPS及并发用户数，做好系统上线以后未来3～5年的数据扩展方案，尽量将网站做成高可扩展性的，这样方便Scale Out（也就是横向扩展，纵向扩展是通过增添机器硬件的方式来实现的），说直白点就是能够很方便地增添新机器。此外，还需要考虑如下因素：
- 重要的对外服务尽量以Linux集群的形式部署，以避免因单机宕机而中断服务。
- 存放数据的磁盘类型可以考虑用LVM逻辑卷，方便扩容。
- 机房需要考虑是否异地冗余，以便在核心机房出问题时快速切换。

另外，要考虑在业务的高峰期，PV、UV及QPS迅速增加、增大的时候，Linux集群能否马上提供应急机器。而在非业务高峰期，因为应急而上线的机器又该如何平稳的下线。当然，要实现这些功能，完全可以利用Kubernetes/Mesos集群的副本机制做扩容和缩容，在用户请求高峰期，它能够对资源进行横向扩容，反之，当用户请求回落低谷的时候，能够及时缩减资源，避免资源的浪费。建议在业务非繁忙期尽量做好单Pod性能压测，掌握单Pod在resources limit限制下的并发连接数的极限，这样才能在系统遇到业务激增的情况下，做到有目的的扩容。

思考一个问题，容器云集群可以利用Kubernetes/Mesos的副本机制缩容/扩容，传统领域又应该如何设计呢？

#### 合理选用开源软件方案
首先是硬件的选择，现在的硬件虽然性能卓越，稳定性也很强，但价格确实比较贵，站在长期运营的角度考虑，使用开源软件应该是我们的首选；另外，如果选用云平台，运营也得控制成本。

对于负载均衡软件，IBM的服务器确实性能强悍，但价格昂贵。事实上，自前端有了负载均衡设备以后，廉价的服务器甚至PC机器都可以以Linux集群的方式给我们提供稳定的服务，因此可以考虑使用免费开源的LVS//HAProxy集群方案。

对于存储，EMC的高端存储确实不错，但同样存在价格昂贵的问题，可以考虑以国产龙存作为替代。另外可以考虑分布式文件系统，例如ClustgerFS或京东的ChubaoFS，这两个分布式系统还提供CSI插件支持，可以应用于Kubernetes或Mesos系统。现在Kubernetes的比重越来越大，我们考虑分布式文件系统时一个较重要的指标就是看它们能不能提供CSI插件支持。

至于数据库，Oracle RAC商用集群的价格不菲，可以考虑用免费的MySQL来设计数据库架构，一主多从。现在有很多优秀的开源方案都可以提供高可用支撑，例如MySQL MHA或者mysql-utilities工具。
缓存方面，Varnish/Nginx和Redis/MongoDB这些软件虽然是开源免费的，但性能并不亚于商业软件，完全可以考虑在自己的系统中合理利用它们。

消息队列可以考虑Kafka或RabbitMQ集群，这也是目前比较通用的开源方案。

ZooKeeper和Etcd都是非常优秀的分布式协调系统，ZooKeeper起源于Hadoop生态系统，Etcd的流行是因为它是Kubernetes的后台支撑。

而大数据组件，可以考虑下原生的Hadoop、Spark和ElasticSearch等。


#### 机房及CDN选型

机房的选型也比较重要，我们到底是选择机房托管还是采用云计算平台呢？这要根据业务的实际情况来定了。

如果业务系统的小图片过多，为了加快用户的访问速度和提升用户体验，建议租用CDN，不推荐自建CDN。因为这样做，成本和性能都不成正比，除非是要提供专业的视频或图片服务的网站。站在用户体验的角度，建议大家采用BGP机房，最少要选用双线机房。也可以根据业务选型来选择机房。

如果是提供资讯类服务的网站，建议采用机房托管的方式（即私有云方式），自建机房的成本较高。

如果是专业的电子商务网站，牵涉在线交易系统，建议选用机房托管的方式；如果自己有机房那就最好了，记住，核心业务要放在自己能掌控的范围之内。

如果是CPA或DSP等广告系统，由于牵涉多地区布点的问题，建议采用公有云的方式，推荐亚马逊云。

如果仅仅是自己的门户网站，从性价比的角度考虑，推荐阿里云、腾讯云或华为云。

#### CI/CD及蓝绿部署发布

随着云原生容器技术的流行，CI/CD流水线（包括蓝绿发布）工作变得越来越简单，我们可以较轻松地完成开发环境、测试环境、预发布环境及线上环境的CI/CD流水线部署工作。

至于应用的蓝绿部署发布，可以考虑Istio服务网格或Nginx Ingress-Controller。作为一个服务网格系统，Istio为服务间通信提供了稳定性、透明性和安全性的保障。不论是集群内还是集群外的服务，只要访问目标是网格内的服务，就都会被Istio拦截并进行处理。

Istio服务网络有很多功能，例如服务间通信的加密、自动地采集指标记录、确定访问控制策略、限制频率及配额等，这里仅着眼于最常用的流量管理能力。Istio让DevOps团队有能力为内部服务创建智能的路由规则。断路器、超时和重试之类的服务级属性非常容易配置，配置（包含蓝绿部署）的过程也很轻松。

当然，如果大家觉得Istio实施复杂，可以考虑使用轻量级的Nginx Ingress-Controller来实现。

#### 系统安全问题
在安全方面，主要需要考虑以下几个方面：
- 需要硬件防火墙吗？有没有应对DDoS的措施。
- 如果是金融类网站，如何保证支付安全，多域名的HTTPS支持呢？
- 核心数据有没有考虑异地容灾备份？
- 如何保证代码和系统的安全，如何控制项目组成员的访问权限？
- 公司系统有没有配置好VPN，做好黑白名单访问限制？


综上所述，网站系统架构设计需要考虑的地方非常多，要全面规避风险，需要系统架构师有足够的经验，他要根据网站的冗余及可扩展性、异地备份容灾、控制成本等要求，针对自己的公司业务设计一个最优的配置方案。事实上，好的架构不是设计出来的，而是演进出来的。网站系统架构上线以后，会在严酷的生产环境下历经各种考验，其中包括外部流量的自然访问压力、内部人员的误操作和服务自愈等，经过我们的不断完善，它最终会演进成一个较完美的形态。


### 千万级PV、高性能、高并发网站的架构设计

网站背景：这是一个TO C的电子订单系统，平时主要针对企业下电子订单，后期改成了个人也能下订单，即同时具备TO B和TO C功能，并且为了拉人气，还在特定的节假日和公司周年庆中增加了抢红包功能。

想象一下，随着网站知名度的提高，注册用户已超过千万，而且每天都有持续增长的趋势，PV/日已经有向千万/日靠拢的趋势，原有的Web架构已无法满足公司需求。这时候要设计一个高性能、高可用的网站架构。在这套架构里，系统架构师应该做的是提升站点整体的性能、可用性，不仅是前端代理，后端应用服务器、数据库、中间件等都要综合考虑。这个架构里任何一个点存在瓶颈，整个系统的处理能力就大打折扣。

由于会牵涉用户信息及第三方支付等敏感信息，因此采取的是物理服务器+IDC机房托管的方式。

机房选择的是BGP机房。BGP机房的优势如下：
- 服务器只需要设置一个IP地址，最佳访问路由是由网络上的骨干路由器根据路由跳数与其他技术指标确定的，不会占用服务器的任何系统资源。服务器的上行路由与下行路由都能选择最优的路径，所以能真正地实现单IP的高速访问。
- 由于BGP协议具有冗余备份、消除环路等特点，因此当IDC服务商有多条BGP互联线路时可以实现路由的相互备份，在一条线路出现故障时路由会自动切换到其他线路。
- 使用BGP协议还可以使网络具有很强的扩展性，可以将IDC网络与其他运营商互联，轻松实现单IP多线路，做到所有互联运营商的用户访问都很快，这是双IP双线无法比拟的。

#### 1.硬件防火墙（可选）
硬件防火墙有路由和透明两种模式，选哪种要根据具体环境而定。防火墙的型号一般选择华赛或Juniper，大家可以根据自己业务网站的实际需求来加以选择，硬件防火墙的主要作用是防DDoS攻击和端口映射。当然，因为网站基本都会使用CDN服务，所以是否增加硬件防火墙是可以选择的。

如果网站是用于电子商务支付系统的，建议前端放置硬件防火墙，国内的DDoS攻击非常流行，对付DDoS攻击是一个比较复杂而庞大的系统工程，想仅仅依靠某种系统或产品防住是不现实的。可以肯定的是，虽然完全杜绝DDoS攻击目前不可能，但通过适当的措施抵御90%的DDoS攻击还是可以做到的。攻击和防御都有开销成本，若通过适当的办法增强了抵御DDoS攻击的能力，也就意味着加大了攻击者的攻击成本，那么绝大多数攻击者将因无法继续下去而选择放弃，也就相当于成功地抵御了DDoS攻击。

#### 2.前端CDN缓存
对于图片量较多的电子商务网站和新闻资讯类网站来说，前端CDN缓存的意义重大：可加快全国用户访问本地网站的速度，从而提升用户体验；还可以在网站遇到DDoS攻击的时候，分流流量，保护核心网站。但使用哪种CDN系统更好呢？这里也面临着两种选择：自己搭建CDN系统或租赁别人的CDN。个人觉得自己搭建CDN系统是件非常消耗财力和人力的事情，而且达不到预期目标，如果需要进行前端缓存，建议以租赁CDN为主，把更多的资金流投入后端的文件存储和NoSQL缓存服务及数据库上去。

#### 3.负载均衡器
对于负载均衡器，根据它们的特点来挑选即可，LVS的性能最好，特别是后端的节点超过10个以上时，但它对网络的要求高，而且不支持动静分离，所以建议暂时不考虑。HAProxy的性能优异，稳定性强，自带强大的监控页面，并且支持动静分离，笔者公司已用HAProxy+Keepalived实现了亿级/日的网站（双万M网卡+bond绑定）。在高并发的业务时间段，单HAProxy也是非常稳定的，没有发生过宕机的情况。

在大公司的网站架构里，多级负载均衡也是很好的设计方案。最外面流量的负载均衡用硬件负载均衡器（例如F5/NetScaler，用于对流量进行转发）实现，以HAProxy或Nginx作为两层负载均衡，根据频道或业务来分流。有读者参考淘宝的架构，说网站最前端一定要放四层负载均衡，这个架构其实是针对淘宝这种巨量级别（几十亿PV/日）的，如果是千万级PV/日的网站，甚至是亿级PV/日的网站，用HAProxy+Keepalived基本就可以满足需求。另外，通过观察高流量网站的HAProxy负载情况，我们发现HAProxy在高并发的情况下还是比较耗CPU和内存资源（尤其是CPU资源）的，建议大家在此架构中采用高性能的服务器，比如PowerEdge R940或更高型号的机器。

HAProxy相对于LVS的优势如下：
- 配置简单，语法通俗易懂。
- HAProxy对网络的依赖性小，理论上只要是能ping得通的网络就可以部署实施七层负载均衡。
- 可实现完美的四层TCP代理转发功能。
- 根据URI路由规则来进行动静分离。
- 根据应用配置URI路由规则并集中热点来提高缓存的命中率。

#### 4.Web缓存层
Web缓存层的搭建可以使用Squid或Varnish。笔者在不少项目中应用过Squid服务器，它作为老牌的反向代理服务器，在生产环境下的稳定性是有保证的。但Squid对多核CPU支持得不好，大家可以尝试使用新兴的Varnish，它的稳定性和性能上不亚于Squid，而且支持多核CPU，性能也优于Squid。

为什么前端已经有CDN缓存，还需要自己架设Web缓存层呢？如果你有高并发高流量的项目经验，应该会发现，后端文件服务器的I/O压力是巨大的（尤其是那种提供海量小图片的网站），有时甚至会发生拒绝提供服务的现象，有了这层Web缓存，可以加速后端Web服务及减少（或本地存储）文件服务器磁盘的I/O压力。

#### 5.Web服务器及Servlet容器
关于Web服务器的选择，Apache作为Web传统服务器，用于电子商务、电子广告、页游等网站是非常稳定的，在8GB内存的标准配置下，其抗并发能力也是非常不错的。许多公司的网站架构其实都是由一台Apache Web服务器发展起来的（公司高层要求平滑不中断业务升级）。如果是访问量比较大的网站，建议用Nginx作为Web服务器。

如果是每天的访问量为千万PV级别的网站，在业务高峰期PV有可能过亿，推荐用Java语言作为网站的核心开发语言。关于Servlet容器，可以考虑Tomcat和Jetty，尤其是Jetty，在我们的微信营销网站中，它的表现优异。利用Nginx配合Jetty，单机能够承受两万左右的并发连接。一些Web聊天应用非常适合用Jetty做服务器，像淘宝的Web旺旺就是用Jetty作为Servlet容器的。而站在技术团队选型的角度，现在Java开发比较成熟，Dubbo、Spring Cloud都已经是很成熟的服务框架，并且很容易嵌入Jetty服务器。

#### 6.文件服务器层
经过后期的宣传策划，网站的客户越来越多，原先的DRBD+Heartbeat+NFS高可用文件服务器和图片存储的磁盘I/O压力越来越大，这时就应该考虑采用分布式文件存储方案了，GlusterFS或ChubaoFS在国内现在也很流行。

虽然分布式文件存储对于减轻文件服务器压力有所帮助，但它们占用机器的数量还是比较多的，维护起来比较复杂；而单NFS维护起来非常容易，事实上在有前端CDN和缓存层的前提下，还可以针对文件服务器进行NFS分组，这样在业务层面就可以更进一步减小NFS的压力了。

对于图片服务器，建议采用独立域名而非二级域名方式，原因如下：
- 避免传输不必要的cookie，从而提升速度，减少不必要的攻击，因为跨域是不会传输cookie的。
- 此外，多个域名可以增加浏览器并行下载条数，因为浏览器对同一个域的域名下载条数是有限制的。

#### 7.数据库缓存及Session
数据库缓存的开源软件比较多，Redis、Memcached等NoSQL数据库作为数据库缓存都非常成熟，它们在减轻数据库读写压力方面效果显著，事实上，很多业务数据放在Redis的效果要远比放在MySQL里好得多，比如IP数组业务数据，一次导入量动辄十几亿条，放在Redis里面的读取速度远远要优于MySQL，同时也会大大减轻MySQL数据库的压力。这里要注意一个情况，虽然我们可以用Redis来提升网站性能，但也有一个弊端，如果需要Cache的数据对象非常多，应用程序要增加的代码量也就会很多，同时网站的复杂度及维护成本也会直线上升，这时就需要开发部门和系统部门的同事协同工作了。

Session数据默认是在各个服务器上分别存放的，客户端发送一个请求，该请求很有可能会被发送到集群中的另外一台机器上，这就会导致Session丢失。所以这里采用一台独立的Memcached或Redis服务器来存储整个网站的Session数据，用以解决各个服务器中Session不同步的问题。

不推荐将Session放进MySQL的做法，在高流量的网站中，数据库的压力是非常大的，不应该再让Session增加数据库的压力了。另外，也不推荐采用Session复制的方式，Session复制的原理是通过组播的方式进行集群间的Session共享，比如我们常用的Tomcat目前就具备这样的功能。优点是Web容器支持，配置简单，这种处理Session的方式适合中小型网站。缺点是当一台机器上的Session变更后，会将变更的数据以组播的形式分发给集群间的所有节点，对网络和所有的Web容器都存在开销，集群越大浪费越严重。系统架构师可以根据网站的实际情况来选择是否采用这种做法。

秒抢红包或红包定时领取是我们需要考虑和设计的场景，像这种用户在瞬间涌入产生高并发的请求，就需要引入消息中间件了，如RabbitMQ或Kafka，集群规模视业务数据而定。

场景中的红包定时领取或秒抢红包都是高并发的业务，活动用户会在到点的时间涌入，MySQL数据层瞬间接受这一记暴击，若支撑不住就会宕机，影响整个业务。

像这种在某时间点高并发地插入或者更新数据的业务（不仅仅有查询的操作），前面提到的通用方案就无法支撑了，并发的时候都是直接命中MySQL数据层；设计这块业务的时候可使用消息队列，将参与用户的信息添加到消息队列中，然后再写个多线程程序去消耗队列，给队列中的用户发放红包。

#### 数据库的压力
数据库经常是整个网站的性能瓶颈所在，所以我们要投入足够多的精力在这上面。网站上线以后，如果数据库读写压力巨大，磁盘I/O负载越来越高，这时应该怎么办呢？
1. 数据库架构可以采用一主多从、读写分离的方案，用HAProxy作为从数据库的负载均衡器，读写通过程序实现分离，前后台业务逻辑分离，针对后台的查询我们全部转到slave机器上，这样就算查询的业务量大也不会影响主要的业务逻辑。
2. 对网站的业务数据库进行分库，后面的业务都是一组数据库，如Web、BBS、Blog等，对主要的业务数据库进行数据的水平切分或垂直切分也是非常有必要的。
3. 数据层的读写分离开源组件我们测试过很多，包括现在较流行的MyCat，感觉都不能百分之百满足需求，建议在程序设计之初就确定好，尽可能地在程序级别来实现。

综上所述，设计这种高流量高并发的网站系统架构，应该尽量做到以下几点：
- 尽量把用户往外面推，保证源站的压力小；
- 网站测试阶段尽量做好压力测试工作；
- 保证网站的高可用性；
- 保证网站的高可扩展性；
- 多利用缓存技术来减轻后端数据库的压力；
- 适当引入消息队列来进行流量削峰；
- 合理优化数据库。

做到了以上几点，我们的网站应该就能承受更大流量和并发的冲击了。


### 亿级PV、高性能、高并发网站的架构设

事实上，如果网站每天达到亿级PV甚至10亿级PV的访问量，那么这是一个相当惊人的数字，这么大的进出量，对系统整体水平的要求是很高的，不仅仅是服务器层面有压力，对代码、数据库、缓存乃至文件系统都是有要求的。对于一个高并发高流量的网站来说，任何一个环节的瓶颈都会造成网站性能下降，影响用户体验，从而造成无法弥补的损失。下面就以笔者维护过的DSP大型电子广告系统为例来说明，7个数据中心，每天日PV接近50亿，平均10万至15万QPS，业务机器单机并发连接数在2.2万至2.8万左右。

那么什么是DSP平台呢？参考百度百科的介绍：

互联网广告DSP（Demand-Side Platform），就是需求方平台。DSP这一概念起源于网络广告发达的欧美，是伴随着互联网和广告业的飞速发展新兴起的网络广告领域。它与Ad Exchange和RTB一起迅速崛起于美国，已在全球快速发展，2011年已经覆盖欧美、亚太地区以及澳洲。在世界网络展示广告领域，DSP方兴未艾。DSP传入中国，迅速成为热潮，成为推动中国网络展示广告RTB市场快速发展的主要动力之一。

一个真正意义的DSP，必须拥有两个核心特征，一是拥有强大的RTB（Real-Time Bidding）的基础设施和能力，二是拥有先进的用户定向（AudienceTargeting）技术。

DSP对其数据运算技术和速度要求非常之高。从普通用户在浏览器中地址栏输入网站的网址，到用户看到页面上的内容和广告这短短几百毫秒之内，就需要发生好几个网络往返（Round Trip）的信息交换。Ad Exchange首先要向DSP发竞价（bidding）请求，告知DSP这次曝光的属性，如物料的尺寸、广告位出现的URL和类别，以及用户的Cookie ID等；DSP接到竞价请求后，也必须在几十毫秒之内决定是否竞价这次曝光，如果决定竞价，出什么样的价格，然后把竞价的响应发回到Ad Exchange。如果Ad Exchange判定该DSP赢得了该次竞价，那么要在极短时间内把DSP所代表的广告主的广告迅速送到用户的浏览器上。整个过程如果速度稍慢，Ad Exchange就会认为DSP超时而不接受DSP的竞价响应，广告主的广告投放就无法实现。

基于数据的用户定向（Audience Targeting）技术，则是DSP另一个重要的核心特征。从网络广告的实质上来说，广告主最终不是为了购买媒体，而是希望通过媒体与他们的潜在客户即目标人群进行广告沟通和投放。服务于广告主或者广告主代理的DSP，则需要对Ad Exchange每一次传过来的曝光机会，根据关于这次曝光的相关数据来决定竞价策略。这些数据包括本次曝光所在网站、页面的信息，更为关键的是本次曝光的受众人群属性，人群定向的分析直接决定DSP的竞价策略。DSP在整个过程中，通过运用自己人群定向技术来分析，所得出的分析结果将直接影响广告主的广告投放效果。

考虑到业务涉及世界各地，7个数据中心需要在全球化部署，业务高峰期能够快速地增添机器以应付暴增流量，并且业务需要通过Hadoop/Spark分析数据，还要考虑稳定的存储文件系统及业务高峰期的机器扩容等问题，而这些AWS都有相应的产品，可以极大地降低运维成本。因此最终考虑采用AWS云计算平台。

下面将DSP系统架构图按照层级的方式逐一说明。


#### 1.负载均衡层
实际上，网站面对这么大的流量冲击，我们的第一反应就是采用一级分流的方式。一般来说，DNS轮询是种常用的做法，我们可以利用DNS轮询将流量第一时间分散到几个数据中心，这里其实用到了分布式的思想，为了不至于让其中的一个数据中心因为顶不住流量而出现宕机的情况，因此选用的是PowerDNS。

在DSP这种流量规模的系统中，还应该关注另一个参数QPS，即Queries Per Second，意思是“每秒查询率”，即系统每秒能够完成的查询次数，是对一个特定的查询服务器在规定时间内所处理流量的衡量标准。之所以应该关心这个数值，是因为它是系统整体性能的重要参考标准。

中间层的负载均衡器采取的是常见架构，用的是Nginx。因为是AWS EC2中的每台机器能够分配的带宽有限，机器很容易被流量打满。所以我们除了使用常规的开源软件监控流量以外，还自己开发了监控工具来进行监控。

我们选用Nginx作为其中间层的负载均衡，作用有以下几点。
- 七层负载均衡，实现各种规则转发。
- 管理业务接口。
- 灰度发布。我们可以利用Nginx的权重算法，将流量分散到线上某台测试机器，如果代码不能顺利通过，也只会影响到这台测试机器。
- 反向代理静态页面缓存，加快用户访问速度。
- 
进来的流量经过这样处理以后，基本上可以分流到各数据中心上面，但有一点要注意，Nginx作为二级负载均衡的压力很大，平时要注意监控以下三种数据。
- 监控Nginx的系统负载及CPU利用率。
- 监控其带宽总体使用情况。
- 后端bidder机器的响应时间（响应时间很重要，这个是DSP系统的性能评估参数之一）。

#### 2.Web应用服务器
主要的业务机器是bidder机器，用于竞标价格。bidder机器选用的是Nginx+Lua（Ngx_lua模块），那么什么是Ngx_lua模块呢？

Ngx_lua是Nginx的一个模块，可将Lua嵌入Nginx中编写脚本，把Lua编写的应用脚本部署到Nginx中运行，Nginx就变成了一个Web容器；这样开发人员就可以使用Lua语言来开发高性能Web应用了。

Ngx_lua提供了很多与Nginx交互的API，对于开发人员来说只需要学习这些API就可以进行功能开发。接触过Servlet的都知道，Ngx_lua的开发和Servlet类似，无外乎就是实现接收请求、参数解析、功能处理、返回响应等功能。

理论上可以使用Ngx_lua开发各种复杂的Web应用，不过Lua是一种脚本/动态语言，不适合业务逻辑比较重的场景，它适合小巧的应用场景（代码行数保持在几十行到几千行）。目前见到的一些应用场景如下。
- Web应用：会进行一些业务逻辑处理，甚至进行耗CPU的模板渲染，一般流程是MySQL/Redis/HTTP获取数据→进行业务处理→产生JSON/XML/模板渲染内容。
- 接入网关：实现如数据校验前置、缓存前置、数据过滤、API请求聚合、AB测试、灰度发布、降级、监控等功能。
- Web防火墙：可以实现IP/URL/UserAgent/Referer黑名单、限流等功能。
- 缓存服务器：可以对响应内容进行缓存，减少到后端的请求，从而提升性能。
- 其他：如静态资源服务器、消息推送服务、缩略图裁剪等。

如何在接入层处理高峰期流量呢？

线上系统主要用AWS的c3.xlarge（4vCPU，14GB）来运行Nginx+Lua，在线上运行时，若并发连接数超过2.4万，则基本带宽就会被打满（虽然AWS没有带宽限制，但由于是多虚拟机共享了物理机的网络性能和I/O性能，因此导致c3.xlarge的带宽限制大约在40～50MB），CPU的利用率在90%左右，系统负载不到4。

机器带宽被打满的现象也很好识别：CPU利用率没有达到100%，而且机器的Nginx+Lua应用也没死掉，但新的连接已经进不去了（Prometheus的网卡监控此时会频繁报警）。

为了处理业务高峰期的流量，一般会同时增添20台左右的bidder机器，AWS的AMI（映像复制）功能使用起来非常方便，而且Instance可以按照小时收费，这极大地降低了运营成本。这块我们是直接利用Python的Boto3模块调用AWS的控制台接口，来实现自动加机器功能的。

网站前台主要是针对客户的，跟常见的CMS系统类似，开发语言主要是PHP。Hadoop/Spark数据分析这块则主要是Java和Python。由于整个系统（包知子系统）涉及的开发语言比较多，因此以Python作为胶水语言，把系统的各个子模块都衔接了起来。后续考虑引入消息中间件，这样各子系统能更好地耦合。

#### 3.数据缓存层

DSP系统会产生大量ip list、domain、关键词等数据，为了实现对这些数据进行快速且有效读取的目的，之前考虑将其放在MySQL数据库上，后面发现存在着速度问题，而且ip list的数据量太大，每次导入都是十几亿条，可见需要一个数据缓存的解决方案。在比对测试了Memcached和Redis的速度后，最终选择了Redis。在将Redis应用到线上环境时，我们也在软硬件及数据结构方面对Redis进行了如下优化：
- 选用EC2内存型实例（r3.xlarge或r3.2xlarge）来运行Redis机器。
- 针对Redis数据结构进行了重组优化。
- 将运行Redis集群机器的数量提高到10～15台（每个数据中心的机器数量视具体情况而定）。

由于DSP广告系统提供的是服务（bidder机器发送的是竞价请求），即无状态的HTTP访问请求，并非传统型的网站，所以此系统并不需要关心这Session共享的问题，而大型网站肯定要关注，建议利用Redis缓存服务器来解决，其优势就是快，大量Session数据的存放和读取完全没有问题。而Redis的主从方案，则可以避免Redis的单点问题。

对于Redis集群机器，我们是通过自己开发的一致性Hash算法程序来统一进行管理的，方便控制，但也有不少问题，比如支持失败节点自动删除、存在程序的单点故障等。目前在尝试用Codis集群来管理。

Codis集群采用一层无状态的Proxy层，将分布式逻辑写在Proxy上，底层的存储引擎还是Redis主从（这种设计很聪明），数据的分布状态存储于ZooKeeper集群（一般是3台，以集群方式提供服务）中，底层的数据存储变成了可插拔的部件。这样做的好处是各个部件可以动态水平扩展，尤其无状态的Proxy，对于动态的负载均衡来说意义还是很大的，而且还可以做一些有意思的事情，比如发现一些slot的数据比较冷，可以专门用一个支持持久化存储的ServerGroup来负责这部分，以节省内存，当这部分数据变热时，再动态地迁移到内存的Server Group上，一切对业务透明。

#### 4.数据库层面的高可用方案

由于数据读取的压力全部在Codis集群上面，分散到后端的MySQL压力不大，因此要考虑它的高可用性。对此，这里也设计了两套方案。
1. MySQL MHA方案
    这是较成熟的MySQL高可用方案，经过了非常严苛的基准测试和混乱测试，数据的一致性还是得到了确认的（这点很重要）。
2. MySQL utilities工具的二次开发
    这里主要选取了两个HAProxy提供对外服务（主要是考虑冗余）。MySQ utilities用于MySQL Failover，其中还会涉及一定的开发工作，即MySQL主从发生变化的时候，需要程序将真正的Master机器IP刷新到HAProxy的配置中，并且进行重载。程序的实现其实较简单，使用Python及Java均可，但这里消耗的机器数量较多。

MySQL utilities和MySQL MHA最大的区别在于是否用了GTID复制，这可以视具体业务来选择。

#### 5.大数据分析
实现大数据分析时，主要是采用的是开源组件，参考了美图、魅族及马蜂窝的大数据设计架构。我们最终选择的是偏传统型的大数据架构，例如Hadoop/Spark、Kafka、Hive、HBase及ElasticSearch等分布式集群，其实主要考虑的是以下功能。
- 分布式计算：即让多个节点并行计算，强调数据的本地性，尽可能地减少数据的传输，例如Spark通过RDD的形式来表现数据的计算逻辑，可以在RDD上做一系列的优化，从而减少数据的传输。
- 分布式存储：所谓的分布式存储，指的是将一个大文件拆成N份，并将每一份独立地放到一台机器上，这里就涉及文件的副本、分片及管理等操作，分布式存储的主要优化动作都在这一块（主要用的是HDFS）。
- 检索和存储的结合：在早期的大数据组件中，存储和计算相对单一，但是目前更多的方向是在存储上做更多的手脚，让查询和计算更高效。对于计算来说，高效不外乎就是查找、读取数据块，所以目前的存储不单单是存储数据内容，同时还会添加很多元信息，例如索引信息。我们在ElasticSearch做了很多的优化工作，来保证搜索效率。

#### 6.Amazon S3文件系统
我们是利用Amazon EMR来运行Hadoop/Spark数据的，业务高峰期间还需要开启大量Spot Instance机器来并行处理数据，数据分析及访问的海量日志均存放在Amazon S3文件系统上分析汇总，再交由下端的业务系统处理。Amazon S3具有高度持久性、可扩展性、安全性、快速且物美价廉的存储服务。借助EMR文件系统，Amazon EMR可以将Amazon S3安全高效地用作Hadoop的对象存储。Amazon EMR对Hadoop进行了大量的改进，因此我们可以无缝地处理Amazon S3中存储的大量数据。

除此之外，Amazon S3在这里还承担了重要的业务数据及数据库文件的备份任务，并且还是Jenkins系统的artifact文件存储。

#### 7.DevOps运维开发工作

目前经过自动化运维工具和开发组同事的努力，已经完成如下工作：

- bidder业务机器的自动增加或删减。
- 分布式爬虫程序的Spot Instance自动增加或删减。
- Redis的一致性Hash算法程序的逐步完善。
- 线上机器的公私钥批量更换或增加（前期是Fabric，后期改用Ansible）。
- 自动化配置管理主要采用Ansible工具，少量运维自行开发。
- CI/CD的具体实现。CI主要采取的Jenkins集群，CD前期主要是用Fabric，后期改用Ansible。
- 灰度上线。应用先在流量较小的数据中心发布，然后观察和监控，等稳定一定时间以后，再逐步在其他数据中心发布，最后才在最核心的数据中心发布上线。
- 图片服务做成了CDN模式提供对外服务（主要是美国数据中心）。

Fabric/Ansible在DevOps工作中的比重很大，熟悉Fabric的读者应该了解得比较多，Fabric是轻量的，很容易跟业务Python代码结合，完成自动化配置管理，但它也存在着很多不足，比如说不支持模板渲染、不支持YAML编排，运维模块没有Ansible丰富等。

而后期我们改用Ansible的原因在于，Ansible拥有丰富的相关支持，包括很多现有的组件和模块，以及开源的部署脚本等。笔者也尝试使用了市面上所有的自动化运维和自动化配置工具，发现Ansible是对AWS支持得最好的一个。Ansible的开发过程是写大量的Playbook（跟Kubernetes容器编排类似），现在Ansible支持的有251个模块，特别是对于云原生的支持，像AWS、Docker、OpenStack和部署脚本都放在一个子目录下，这就意味着把别人写的脚本拿过来，或者把别人写定义的Playbook拿过来非常容易。现在关于Ansible的开源脚本数量庞大，大约有3000多个项目，相信这个数字只会越来越多，这意味着以后很多的DevOps工作都会越来越简单容易。

#### 8.Docker技术的选择
经过严格的性能测试比对，我们发现Docker对网络性能还是有一定损耗的，所以这里采用的是Nginx+Lua源码安装部署方式，而没有采取Docker的方式，只有Prometheus+Grafana等监控组件和部分应用采取了Docker的方式。

为了方便迁移和水平扩容，Jenkins集群采取的是Docker化的部署方式。

Docker云平台采取的是Mesos/Marathon管理，它具有稳定、功能单一等特点，运维成本较低。

#### 9.压力测试及其他
系统上线前，测试组的同事会用Load Runner对主要业务机器bidder进行大量的压力测试。系统上线前及上线后，我们也会密切关注以下方面：
- Nginx负载均衡机器的带宽使用情况。
- 系统的整体QPS/TPS情况，尤其在业务的高峰时期。
- 系统整体的响应时间。
- bidder机器的并发连接总数和带宽使用情况。
- bidder机器的负载、CPU利用率、内存使用情况。
- Redis分布式集群机器的内存使用情况。
- Scrapy分布式爬虫中Spot Instance的运行情况。
- ElasticSearch集群的全文搜索效率。

经过大家的共同努力，我们的业务平台已经能抵受很大流量的冲击，很多新技术也在慢慢融入进来，功能也在日趋完善。随着业务的调整，系统的整体架构也在做相应的优化调整，一切以稳定为最高原则。

### 秒杀系统的架构设计

如果在业务中遇到了秒杀这种极端场景，我们应该如何来处理呢？

比如说京东秒杀，就是一种定时定量的秒杀，在规定的时间内，无论商品是否秒杀完毕，该场次的秒杀活动都会结束。这种秒杀，对时间要求不是特别严格，只要下手快点，秒中的概率还是比较大的。

#### 1.业务特点
- 瞬时并发量大：秒杀时会有大量用户在同一时间进行抢购，瞬时并发访问量突增10倍，甚至100倍以上的都有。
- 库存量少：一般参与秒杀活动的商品量很少，这就导致了只有极少量用户能成功购买。
- 业务简单：流程比较简单，一般都是下订单、扣库存、支付订单。

#### 2.技术难点
- 现有业务的冲击：秒杀是营销活动中的一种，如果和其他营销活动部署在同一服务器上，肯定会对现有的其他活动造成冲击，极端情况下可能导致整个电商系统服务宕机。
- 直接下订单：下单页面是一个正常的URL地址，需要控制在秒杀开始前不能下订单，只能浏览对应活动商品的信息。简单来说，需要Disable订单按钮。
- 页面流量突增：秒杀活动开始前后，会有很多用户请求对应的商品页面，这会造成后台服务器的流量突增，同时对应的网络带宽增加，需要控制商品页面的流量不会对后台服务器、DB、Redis等组件造成过大的压力。

#### 3.系统设计
1. 限流
    由于活动库存量一般都很少，只有少部分用户能秒杀成功。所以我们需要限制大部分用户流量，只准少量用户流量进入后端服务器。
2. 削峰
    键因素。实现流量削峰填谷，一般使用的是缓存和MQ中间件。
3. 异步
    其实可以把秒杀当作高并发系统来处理，可以考虑从业务上做兼容，将同步的业务设计成异步处理的任务，提高网站的整体可用性。
4. 缓存
    秒杀系统的瓶颈主要体现在下订单、扣减库存等流程中。在这些流程中主要用到OLTP的数据库，类似MySQL、Oracle。由于数据库底层采用的是B+树的储存结构，对应我们随机写入与读取的效率，相对较低。如果把部分业务逻辑迁移到Redis中，会极大地提高并发效率。

#### 4.客户端优化
客户端优化主要有如下两个问题。
1. 秒杀页面
    秒杀活动开始前，其实就有很多用户访问该页面了。如果这个页面的一些资源，比如CSS、JS、图片、商品详情等，都访问后端服务器甚至DB，服务肯定会出现不可用的情况。所以我们一般会把这个页面整体进行静态化，并将静态化之后的页面分发到CDN边缘节点上，起到压力分散的作用。
2. 防止提前下单
    防止提前下单主要是在静态化页面中加入一个JS文件引用，该JS文件包含活动是否开始的标记以及开始时的动态下单页面的URL参数。这个JS文件是不会被CDN系统缓存的，它会一直请求后端服务，所以这个JS文件一定要很小。当活动快开始的时候（比如提前0.5～2小时），通过后台接口修改这个JS文件使之生效。

#### 5.API接入层优化
如果用户有一定的网络基础，简单的客户端优化可能起不到防御作用，因此服务端的API接入层也需要加些对应控制，不能信任客户端的任何操作。一般控制分为如下两类：
1. 限制用户维度访问频率
    针对同一个用户（Userid维度）做页面级别缓存，单元时间内的请求统一走缓存，返回同一个页面。其实就这一个工作而言，如果深化，还有很多工作需要做。
2. 限制商品维度访问频率
    大量请求同时间段查询同一个商品时，可以做页面级别缓存，不管下回是谁来访问，只要是这个页面就直接返回。

#### 6.SOA服务层优化
上面两层只能限制异常用户访问，如果秒杀活动运营得比较好，很多用户都参加了，就会造成系统压力过大甚至宕机，因此需要进行后端流量控制。

对于后端系统的控制可以通过消息队列、异步处理、提高并发等方式解决。对于超过系统水位线的请求，直接采取“Fail-Fast（快速失败）”原则拒绝。

秒杀系统核心在于层层过滤，逐渐递减瞬时访问压力，减少最终对数据库的冲击。

压力最大的地方是MQ排队服务，只要MQ排队服务能顶住，后面下订单与扣减库存的压力都是自己能控制的，根据数据库的压力，可以定制化创建订单消费者的数量，避免因为消费者数据量过多，导致数据库压力过大或者直接宕机。

库存服务专门为秒杀的商品提供库存管理，实现提前锁定库存功能，避免出现超卖的现象。同时，通过超时处理任务发现已抢到商品但未付款的订单，并在规定付款时间后，处理这些订单，同时恢复订单商品对应的库存量。

总结秒杀系统的核心思想，即：层层过滤！
1. 尽量将请求拦截在上游，降低下游的压力；
2. 充分利用缓存与消息队列，提高请求处理速度及削峰填谷的作用。
