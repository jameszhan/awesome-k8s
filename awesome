#!/usr/bin/env ruby
require 'thor'
require 'sshkit'
require 'sshkit/sudo'
require 'sshkit/dsl'

SSHKit.config.format = :pretty
SSHKit.config.output_verbosity = :debug

SUDO_USER = ENV['SUDO_USER']
SUDO_PASS = ENV['SUDO_PASS']

class Runner
  include Thor::Base

  def self.batch(&block)
    runner = Runner.new
    runner.instance_eval(&block)
    runner.execute
  end

  def initialize(config = {}, &block)
    @config = config
    instance_eval(&block) if block_given?
  end

  def scripts
    @scripts ||= []
  end

  def run(command, config = {})
    say_status :run, command, config.fetch(:verbose, true)
    scripts << command
  end

  def execute
    command = scripts.join(' && ')
    return if @config[:'dry-run']
    @config[:capture] ? `#{command}` : system(command)
  end
end

class PasswordInteractionHandler

  def on_data(command, stream_name, data, channel)
    case data
      when /password/i
        channel.send_data("#{SUDO_PASS}\n")
      else
        puts "#{command}, #{stream_name}, #{data}, #{channel}"
        channel.send_data("#{SUDO_PASS}\n")
    end
  end

end

class Awesome < Thor
  include Actions
  include SSHKit::DSL

  desc 'user k8s-node003 deploy', 'create new user deploy for k8s-node003'
  def user(hostname, username='deploy', port=22)
    target_host = SSHKit::Host.new(
      hostname: hostname,
      port: port,
      user: SUDO_USER,
      password: SUDO_PASS,
      ssh_options: {}
    )

    pass_cb = PasswordInteractionHandler.new

    on target_host, in: :sequence, wait: 5 do |host|
      if test "[ -d /home/#{username} ]"
        puts "\e[0;32m USER #{username} has already created. \e[0m\n"
      else
        sudo 'useradd -m -s /bin/bash -u 1001 deploy', interaction_handler: pass_cb
        sudo 'usermod -aG sudo deploy', interaction_handler: pass_cb
        sudo 'usermod -aG adm deploy', interaction_handler: pass_cb
        sudo 'usermod -a -G users deploy', interaction_handler: pass_cb
        sudo 'usermod -a -G staff deploy', interaction_handler: pass_cb
      end

      if test "[ -f /etc/sudoers.d/#{username} ]"
        puts "\e[0;32m USER #{username} is already NOPASSWD sudo user. \e[0m\n"
      else
        execute "echo '#{username} ALL = (ALL) NOPASSWD: ALL' > /tmp/sudoer_#{username}"
        sudo :mv, "/tmp/sudoer_#{username}", "/etc/sudoers.d/#{username}", interaction_handler: pass_cb
        sudo :chown, "-R root:root /etc/sudoers.d/#{username}", interaction_handler: pass_cb
        # execute "echo 'deploy ALL = (ALL) NOPASSWD: ALL' | sudo tee /etc/sudoers.d/deploy", interaction_handler: pass_cb
      end

      if test "[ -d /home/#{username}/.ssh ]"
        puts "\e[0;32m /home/#{username}/.ssh have already exists. \e[0m\n"
      else
        # 本地免密码 SSH 登陆
        puts "\e[0;33m /home/#{username}/.ssh not exists, create it. \e[0m\n"

        sudo "mkdir /home/#{username}/.ssh", interaction_handler: pass_cb
        upload! "/home/#{SUDO_USER}/.ssh/id_rsa.pub", '/tmp/id_rsa.pub'
        upload! "/home/#{SUDO_USER}/.ssh/id_rsa", '/tmp/id_rsa'
        upload! "/home/#{SUDO_USER}/.ssh/authorized_keys", '/tmp/authorized_keys'
        # execute "cat /tmp/id_rsa.pub | sudo tee -a /home/#{username}/.ssh/authorized_keys", interaction_handler: pass_cb

        sudo :mv, '/tmp/id_rsa.pub', "/home/#{username}/.ssh/", interaction_handler: pass_cb
        sudo :mv, '/tmp/id_rsa', "/home/#{username}/.ssh/", interaction_handler: pass_cb
        sudo :mv, '/tmp/authorized_keys', "/home/#{username}/.ssh/", interaction_handler: pass_cb

        sudo :chown, '-R', "#{username}:#{username}", "/home/#{username}/.ssh", interaction_handler: pass_cb
        sudo :chmod, '-R', 'go-rwx', "/home/#{username}/.ssh/id_rsa", interaction_handler: pass_cb
      end
    end
  end

  desc 'setup k8s-node003 deploy', 'setup for k8s-node003 via user deploy'
  def setup(hostname, user='deploy', port=22)
    on "#{user}@#{hostname}:#{port}", in: :sequence, wait: 5 do
      if test "[ -f /etc/apt/sources.list_bak ]"
        puts "/etc/apt/sources.list has already updated"
      else
        sudo :mv, '/etc/apt/sources.list', '/etc/apt/sources.list_bak'

        # mirrors_url = 'https://mirrors.ustc.edu.cn'
        mirrors_url = 'https://mirrors.tuna.tsinghua.edu.cn'
        lsb_release_sc = capture(:lsb_release, '-sc')
        if test "[ `lsb_release -si` = Ubuntu ]"
          sources_list = StringIO.new <<~SOURCE_LIST
            deb #{mirrors_url}/ubuntu #{lsb_release_sc} main restricted universe multiverse
            deb-src #{mirrors_url}/ubuntu #{lsb_release_sc} main restricted universe multiverse
            
            deb #{mirrors_url}/ubuntu #{lsb_release_sc}-updates main restricted universe multiverse
            deb-src #{mirrors_url}/ubuntu #{lsb_release_sc}-updates main restricted universe multiverse
            
            deb #{mirrors_url}/ubuntu #{lsb_release_sc}-backports main restricted universe multiverse
            deb-src #{mirrors_url}/ubuntu #{lsb_release_sc}-backports main restricted universe multiverse
            
            deb #{mirrors_url}/ubuntu #{lsb_release_sc}-security main restricted universe multiverse
            deb-src #{mirrors_url}/ubuntu #{lsb_release_sc}-security main restricted universe multiverse
          SOURCE_LIST
        elsif test "[ `lsb_release -si` = Debian ]"
          sources_list = StringIO.new <<~SOURCE_LIST
            deb #{mirrors_url}/debian #{lsb_release_sc} main
            deb-src #{mirrors_url}/debian #{lsb_release_sc} main

            deb #{mirrors_url}/debian-security #{lsb_release_sc}-security main contrib
            deb-src #{mirrors_url}/debian-security #{lsb_release_sc}-security main contrib

            deb #{mirrors_url}/debian #{lsb_release_sc}-updates main contrib
            deb-src #{mirrors_url}/debian #{lsb_release_sc}-updates main contrib
          SOURCE_LIST
        end

        if sources_list
          upload! sources_list, '/tmp/apt-sources.list'
          execute 'cat /tmp/apt-sources.list | sudo tee /etc/apt/sources.list'

          execute 'export DEBIAN_FRONTEND=noninteractive'
          sudo 'apt -y update'
          sudo 'apt -o Dpkg::Options::="--force-confold" upgrade -q -y'
          sudo 'apt -o Dpkg::Options::="--force-confold" dist-upgrade -q -y'
          sudo 'apt -y upgrade'
          sudo 'apt -y dist-upgrade'
          sudo 'apt -y autoclean'
          sudo 'apt -y full-upgrade'
          sudo 'apt -y autoremove'      
        end

        sudo :apt, 'install', '-y', 'coreutils procps libseccomp2 net-tools sysstat rsync bash-completion socat'
      end

      if test "[ -f /etc/hosts.bak ]"
        puts "/etc/hosts has already updated"
      else
        sudo :mv, '/etc/hosts', '/etc/hosts.bak'
        host_conf = StringIO.new <<~HOST_CONF
          127.0.0.1 localhost
          127.0.1.1 #{hostname}
          
          # The following lines are desirable for IPv6 capable hosts
          ::1     ip6-localhost ip6-loopback
          fe00::0 ip6-localnet
          ff00::0 ip6-mcastprefix
          ff02::1 ip6-allnodes
          ff02::2 ip6-allrouters

          192.168.1.61  k8s-master01
          192.168.1.62  k8s-master02
          192.168.1.63  k8s-master03

          192.168.1.101 k8s-node001
          192.168.1.102 k8s-node002
          192.168.1.103 k8s-node003
          192.168.1.104 k8s-node004
          192.168.1.105 k8s-node005
          192.168.1.106 k8s-node006
          192.168.1.107 k8s-node007
          192.168.1.108 k8s-node008
          192.168.1.109 k8s-node009
          192.168.1.111 k8s-node011
          192.168.1.112 k8s-node012
          192.168.1.113 k8s-node013
          192.168.1.114 k8s-node014
          192.168.1.115 k8s-node015
          192.168.1.116 k8s-node016
          192.168.1.117 k8s-node017
          192.168.1.118 k8s-node018
          192.168.1.119 k8s-node019

          192.168.1.6	  synology-ds918.local
          192.168.1.50  pve-5900hx.local
          192.168.1.60  pve-5700u.local
          192.168.1.90  ubuntu-server.local
        HOST_CONF

        upload! host_conf, '/tmp/hosts'
        execute 'cat /tmp/hosts | sudo tee /etc/hosts'
      end

      execute :echo, 'export LC_ALL=en_US.UTF-8', '>> ~/.bashrc' if test '[ -z $LC_ALL ]'
      execute :echo, 'export LANG=en_US.UTF-8', '>> ~/.bashrc' if test '[ -z $LANG ]'
    end
  end

  desc 'ntp k8s-node003 deploy', 'ntp k8s-node003 deploy'
  def ntp(hostname, user='deploy')
    on "#{user}@#{hostname}", in: :sequence, wait: 5 do
      unless test('type chronyd')
        sudo 'apt -y remove ntpd' if test('type ntpd')
        sudo 'apt -y update'
        sudo 'apt -y install chrony'

        sudo 'timedatectl set-timezone Asia/Shanghai'
        sudo 'timedatectl set-ntp true'

        sudo 'cp /etc/chrony/chrony.conf /etc/chrony/chrony.conf.bak' if test "[ -f /etc/chrony/chrony.conf ]"
        chrony_version = capture("chronyd --version | grep -o -E 'version\s*[0-9.]+' | awk '{print $2}'")

        chrony_conf = <<~CHRONY_CONF
          server ntp.aliyun.com iburst
          server cn.ntp.org.cn iburst
          server ntp.shu.edu.cn iburst
          server 0.cn.pool.ntp.org iburst
          server 1.cn.pool.ntp.org iburst
          server 2.cn.pool.ntp.org iburst
          server 3.cn.pool.ntp.org iburst
          
          keyfile /etc/chrony/chrony.keys
          driftfile /var/lib/chrony/chrony.drift
          logdir /var/log/chrony
          
          maxupdateskew 100.0
          rtcsync
          makestep 1.0 3
        CHRONY_CONF
  
        if chrony_version.start_with?('4.')
          chrony_conf =<<~MORE_CONF
            #{chrony_conf}
            confdir /etc/chrony/conf.d
            ntsdumpdir /var/lib/chrony
            sourcedir /run/chrony-dhcp
            sourcedir /etc/chrony/sources.d
            
            leapsectz right/UTC
          MORE_CONF
        end

        upload! StringIO.new(chrony_conf), '/tmp/chrony.conf'
        execute 'cat /tmp/chrony.conf | sudo tee /etc/chrony/chrony.conf'

        sudo :systemctl, 'daemon-reload'
        sudo :systemctl, 'restart', 'chrony'
        sudo :chronyc, 'makestep'
      else
        puts "ntp has already setup"
      end   
    end
  end

  desc 'kernel k8s-node003 deploy', 'kernel k8s-node003 deploy'
  def kernel(hostname, user='deploy')
    on "#{user}@#{hostname}", in: :sequence, wait: 5 do
      unless test "[ -f /etc/modules-load.d/k8s.conf ]"
        sudo 'apt -y update'
        sudo 'apt -y install ipvsadm ipset conntrack'

        k8s_mod_cfg = StringIO.new <<~K8S_MOD
          overlay
          ip_vs
          ip_vs_rr
          ip_vs_wrr
          ip_vs_lc
          ip_vs_wlc
          ip_vs_sh
          ip_vs_dh
          br_netfilter
          nf_conntrack
        K8S_MOD
        upload! k8s_mod_cfg, '/tmp/k8s-mod.conf'
        execute 'cat /tmp/k8s-mod.conf | sudo tee /etc/modules-load.d/k8s.conf'

        k8s_sysctl_cfg = StringIO.new <<~K8S_SYSCTL
          net.bridge.bridge-nf-call-ip6tables = 1
          net.bridge.bridge-nf-call-iptables = 1
          net.ipv4.ip_forward = 1
          net.ipv4.tcp_keepalive_time = 600
          net.ipv4.tcp_keepalive_intvl = 30
          net.ipv4.tcp_keepalive_probes = 10
        K8S_SYSCTL
        upload! k8s_sysctl_cfg, '/tmp/k8s-sysctl.conf'
        execute 'cat /tmp/k8s-sysctl.conf | sudo tee /etc/sysctl.d/k8s.conf'

        sudo 'sysctl --system'

        ulimit_cfg = StringIO.new <<~ULIMIT
          * soft nofile 655360
          * hard nofile 131072
          * soft nproc 655350
          * hard nproc 655350
          * soft memlock unlimited
          * hard memlock unlimited
        ULIMIT
        upload! ulimit_cfg, '/tmp/limits.conf'
        execute 'cat /tmp/limits.conf | sudo tee /etc/security/limits.conf'
        execute 'ulimit -SHn 65535'

        sudo 'sed -i -r "/(.*)swap(.*)swap(.*)/d" /etc/fstab'
        sudo 'swapoff -a'
      else
        puts "kernel optimize has already setup"
      end   
    end
  end

  # https://docs.docker.com/engine/install/ubuntu/
  # https://docs.docker.com/engine/install/debian/
  desc 'docker k8s-node003 deploy', 'docker k8s-node003 deploy'
  option :daemon_json, :type => :boolean, :default => true
  def docker(hostname, user='deploy')
    enable_daemon_json = options[:daemon_json]
    on "#{user}@#{hostname}", in: :sequence, wait: 5 do
      unless test('type containerd')
        # install docker
        execute 'sudo apt remove docker docker-engine docker.io containerd runc' if test('type docker')
        sudo 'apt -y update'
        sudo 'apt -y install ca-certificates curl gnupg lsb-release'

        lsb_release_sc = capture(:lsb_release, '-sc')
        lsb_release_si = capture(:lsb_release, '-si').downcase
        arch = capture(:dpkg, '--print-architecture')
        unless test "[ -f /usr/share/keyrings/docker-archive-keyring.gpg ]"
          # curl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
          # curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
          execute "curl -fsSL https://download.docker.com/linux/#{lsb_release_si}/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg"
        end
        # echo \
        # "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/debian \
        # $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
        execute <<-EOS
          echo 'deb [arch=#{arch} signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/#{lsb_release_si} #{lsb_release_sc} stable' \
          | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
        EOS

        sudo 'apt -y update'
        sudo 'apt -y install docker-ce docker-ce-cli containerd.io'
        if enable_daemon_json
          daemon_json = StringIO.new <<~JSON
          {
            "data-root": "/var/lib/docker",
            "log-driver": "json-file",
            "log-opts": {
              "max-size": "200m",
              "max-file": "5"
            },
            "default-ulimits": {
              "nofile": {
                "Name": "nofile",
                "Hard": 655360,
                "Soft": 655360
              },
              "nproc": {
                "Name": "nproc",
                "Hard": 655360,
                "Soft": 655360
              }
            },
            "live-restore": true,
            "oom-score-adjust": -1000,
            "max-concurrent-downloads": 10,
            "max-concurrent-uploads": 10,
            "storage-driver": "overlay2",
            "storage-opts": [
              "overlay2.override_kernel_check=true"
            ],
            "exec-opts": [
              "native.cgroupdriver=systemd"
            ],
            "registry-mirrors": [
              "https://yssx4sxy.mirror.aliyuncs.com/"
            ],
            "insecure-registries": [
              "harbor.default.svc.cluster.local"
            ]
          }
          JSON
          upload! daemon_json, '/tmp/daemon.json'
          sudo 'mkdir /etc/docker' unless test "[ -d /etc/docker ]"
          execute 'cat /tmp/daemon.json | sudo tee /etc/docker/daemon.json > /dev/null'
        end

        sudo "usermod -aG docker #{user}"
      else
        puts "\e[0;32m docker have already installed. \e[0m\n"    
      end
    end
  end

  desc 'k8s k8s-node003 deploy', 'k8s k8s-node003 deploy'
  option :role, :default => 'master'
  option :dnsip, :default => '192.168.1.130'
  option :cluster_cidr, :default => "10.244.0.0/16"
  option :kube_proxy_mode, :default => 'iptables'
  def k8s(hostname, user=deploy, role='worker')
    role = options[:role]
    core_dns_ip = options[:dnsip]
    cluster_cidr = options[:cluster_cidr]
    kube_proxy_mode = options[:kube_proxy_mode]
    on "#{user}@#{hostname}", in: :sequence, wait: 5 do
      if role == 'master'
        puts "\e[0;32m master node setup script is upcoming. \e[0m\n"
      else
        unless test('type kubelet')
          unless test "[ -d /tmp/kubernetes/server/bin ]"
            execute 'wget --quiet https://dl.zizhizhan.com:8443/binaries/x86_64/kubernetes/kubernetes-server-v1.23.1-linux-amd64.tar.gz --output-document=/tmp/kubernetes.tar.gz' 
            execute 'cd /tmp && tar -zxf kubernetes.tar.gz'
          end

          sudo 'cp /tmp/kubernetes/server/bin/kube-proxy /usr/local/bin'
          sudo 'cp /tmp/kubernetes/server/bin/kubelet /usr/local/bin'
        end

        unless test "[ -d /etc/kubernetes/ssl ]"
          sudo 'mkdir -p /etc/kubernetes/ssl'
          sudo 'mkdir -p /etc/kubernetes/manifests'
          sudo 'mkdir -p /var/lib/kubelet'
          sudo 'mkdir -p /var/lib/kube-proxy'

          execute 'scp -o StrictHostKeyChecking=no k8s-master01:/etc/kubernetes/ssl/ca.pem /tmp'
          execute 'scp -o StrictHostKeyChecking=no k8s-master01:/etc/kubernetes/kubelet-bootstrap.kubeconfig /tmp'
          execute 'scp -o StrictHostKeyChecking=no k8s-master01:/etc/kubernetes/kube-proxy.kubeconfig /tmp'
          sudo 'mv /tmp/ca.pem /etc/kubernetes/ssl'
          sudo 'mv /tmp/kubelet-bootstrap.kubeconfig /etc/kubernetes'
          sudo 'mv /tmp/kube-proxy.kubeconfig /etc/kubernetes'
          sudo 'chown -R root:root /etc/kubernetes'
        end

        lsb_release_si = capture(:lsb_release, '-si')
        if lsb_release_si == 'Ubuntu'
          resolv_conf = "/run/systemd/resolve/resolv.conf"
        else
          resolv_conf = "/etc/resolv.conf"
        end

        # https://kubernetes.io/docs/reference/config-api/kubelet-config.v1beta1/
        unless test "[ -f /etc/kubernetes/kubelet.yaml ]"
          kubelet_yaml = StringIO.new <<~YAML
            apiVersion: kubelet.config.k8s.io/v1beta1
            kind: KubeletConfiguration

            authentication:
              anonymous:
                enabled: false
              webhook:
                cacheTTL: 2m
                enabled: true
              x509:
                clientCAFile: /etc/kubernetes/ssl/ca.pem
            
            authorization:
              mode: Webhook
              webhook:
                cacheAuthorizedTTL: 0s
                cacheUnauthorizedTTL: 0s

            # cgroupDriver: cgroupfs
            cgroupDriver: systemd

            clusterDomain: cluster.local
            clusterDNS:
              - #{core_dns_ip}
            
            staticPodPath: /etc/kubernetes/manifests

            syncFrequency: 1m
            fileCheckFrequency: 20s
            httpCheckFrequency: 20s
            
            address: 0.0.0.0
            port: 10250

            healthzPort: 10248
            healthzBindAddress: 127.0.0.1
            
            # rotateCertificates: false
            rotateCertificates: true
            
            streamingConnectionIdleTimeout: 4h
            nodeStatusUpdateFrequency: 10s
            nodeStatusReportFrequency: 5m
            imageMinimumGCAge: 2m
            volumeStatsAggPeriod: 1m
            
            cpuManagerReconcilePeriod: 10s
            runtimeRequestTimeout: 2m
            
            resolvConf: #{resolv_conf}
            
            evictionPressureTransitionPeriod: 5m
            
            logging:
              flushFrequency: 0
              options:
                json:
                  infoBufferSize: "0"
              verbosity: 0
            
            shutdownGracePeriod: 0s
            shutdownGracePeriodCriticalPods: 0s
          YAML

          upload! kubelet_yaml, '/tmp/kubelet.yaml'
          execute 'cat /tmp/kubelet.yaml | sudo tee /etc/kubernetes/kubelet.yaml > /dev/null'
        end

        # https://kubernetes.io/docs/reference/config-api/kube-proxy-config.v1alpha1/
        unless test "[ -f /etc/kubernetes/kube-proxy.yaml ]"
          kube_proxy_yaml = StringIO.new <<~YAML
            apiVersion: kubeproxy.config.k8s.io/v1alpha1
            kind: KubeProxyConfiguration

            bindAddress: 0.0.0.0
            clientConnection:
              kubeconfig: /etc/kubernetes/kube-proxy.kubeconfig
            clusterCIDR: #{cluster_cidr}

            healthzBindAddress: 0.0.0.0:10256
            metricsBindAddress: 127.0.0.1:10249
            hostnameOverride: "#{hostname}"
            mode: #{kube_proxy_mode}
          YAML

          upload! kube_proxy_yaml, '/tmp/kube-proxy.yaml'
          execute 'cat /tmp/kube-proxy.yaml | sudo tee /etc/kubernetes/kube-proxy.yaml > /dev/null'
        end

        unless test "[ -f /lib/systemd/system/kubelet.service ]"
          kubelet_svc = StringIO.new <<~INI
            [Unit]
            Description=Kubernetes Kubelet
            Documentation=https://github.com/kubernetes/kubernetes
            After=docker.service
            Requires=docker.service
            
            [Service]
            WorkingDirectory=/var/lib/kubelet
            ExecStart=/usr/local/bin/kubelet \\
              --hostname-override=#{hostname} \\
              --bootstrap-kubeconfig=/etc/kubernetes/kubelet-bootstrap.kubeconfig \\
              --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \\
              --config=/etc/kubernetes/kubelet.yaml \\
              --network-plugin=cni \\
              --cert-dir=/etc/kubernetes/ssl \\
              --pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.6 \\
              --alsologtostderr=true \\
              --logtostderr=false \\
              --log-dir=/var/log/kubernetes \\
              --v=2
            
            Restart=on-failure
            RestartSec=5
            
            [Install]
            WantedBy=multi-user.target
          INI

          upload! kubelet_svc, '/tmp/kubelet.service'
          execute 'cat /tmp/kubelet.service | sudo tee /lib/systemd/system/kubelet.service > /dev/null'
        end

        unless test "[ -f /lib/systemd/system/kube-proxy.service ]"
          kubeproxy_svc = StringIO.new <<~INI
            [Unit]
            Description=Kubernetes Kube-Proxy Server
            Documentation=https://github.com/kubernetes/kubernetes
            After=network.target
            
            [Service]
            WorkingDirectory=/var/lib/kube-proxy
            ExecStart=/usr/local/bin/kube-proxy \\
              --config=/etc/kubernetes/kube-proxy.yaml \\
              --alsologtostderr=true \\
              --logtostderr=false \\
              --log-dir=/var/log/kubernetes \\
              --v=2
            Restart=on-failure
            RestartSec=5
            LimitNOFILE=65536
            
            [Install]
            WantedBy=multi-user.target
          INI

          upload! kubeproxy_svc, '/tmp/kube-proxy.service'
          execute 'cat /tmp/kube-proxy.service | sudo tee /lib/systemd/system/kube-proxy.service > /dev/null'

          sudo :systemctl, 'daemon-reload'
          sudo :systemctl, 'enable kubelet'
          sudo :systemctl, 'enable kube-proxy'
          sudo :systemctl, 'restart kubelet'
          sudo :systemctl, 'restart kube-proxy'
        end
      end
    end
  end

  desc 'addons k8s-node003 deploy', 'install addons for k8s-node003'
  def addons(hostname, user='deploy')
    on "#{user}@#{hostname}", in: :sequence, wait: 5 do
      sudo :apt, '-y update'
      sudo :apt, '-y install nfs-common'
    end
  end

  desc 'upgrade k8s-node003 deploy', 'install addons for k8s-node003'
  option :role, :default => 'master'
  option :version, :default => '1.23.1'
  def upgrade(hostname, user='deploy')
    role = options[:role]
    version = options[:version]

    if role == 'master'
      puts "\e[0;32m master node setup script is upcoming. \e[0m\n"
    elsif role == 'worker'
      on "#{user}@#{hostname}", in: :sequence, wait: 5 do
        unless test "[ -f /tmp/kubernetes-v#{version}.tar.gz ]"
          execute "wget --quiet https://dl.zizhizhan.com:8443/binaries/x86_64/kubernetes/kubernetes-server-v#{version}-linux-amd64.tar.gz --output-document=/tmp/kubernetes-v#{version}.tar.gz"
          execute 'rm -fr /tmp/kubernetes'
          execute "cd /tmp && tar -zxf kubernetes-v#{version}.tar.gz"
        end

        
      end
    end
  end

  # https://kubernetes.io/zh/docs/setup/production-environment/tools/kubeadm/
  desc 'kubeadm ubuntu-kubeadm.local deploy', 'install kubeadm for ubuntu-kubeadm'
  option :role, :default => 'worker'
  def kubeadm(hostname, user='deploy')
    role = options[:role]
    on "#{user}@#{hostname}", in: :sequence, wait: 5 do

      unless test "[ -f /etc/modules-load.d/k8s.conf ]"
        # cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
        # br_netfilter
        # EOF
        k8s_mod_conf = StringIO.new <<~CONF
          br_netfilter
        CONF
        upload! k8s_mod_conf, '/tmp/k8s_mod.conf'
        execute 'cat /tmp/k8s_mod.conf | sudo tee /etc/modules-load.d/k8s.conf'
      end

      unless test "[ -f /etc/sysctl.d/k8s.conf ]"
        # cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
        # net.bridge.bridge-nf-call-ip6tables = 1
        # net.bridge.bridge-nf-call-iptables = 1
        # EOF
        k8s_sysctl_conf = StringIO.new <<~CONF
          net.bridge.bridge-nf-call-ip6tables = 1
          net.bridge.bridge-nf-call-iptables = 1
        CONF
        upload! k8s_sysctl_conf, '/tmp/k8s_sysctl.conf'
        execute 'cat /tmp/k8s_sysctl.conf | sudo tee /etc/sysctl.d/k8s.conf'

        sudo :sysctl, '--system'
      end

      unless test('type kubeadm')
        sudo :apt, '-y update'
        sudo :apt, 'install -y apt-transport-https ca-certificates curl'
        
        unless test "[ -f /usr/share/keyrings/kubernetes-archive-keyring.gpg ]"
          # sudo curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg
          sudo :curl, '-fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg'
        end

        unless test "[ -f /etc/apt/sources.list.d/kubernetes.list ]"
          # echo "deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list
          execute <<-SCRIPT
            echo 'deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main' \
            | sudo tee /etc/apt/sources.list.d/kubernetes.list > /dev/null
          SCRIPT
        end

        sudo :apt, '-y update'
        sudo :apt, 'install -y kubelet kubeadm kubectl'
        sudo 'apt-mark hold kubelet kubeadm kubectl'
      end

      fstab = capture('cat /etc/fstab')
      if fstab.include?('swap.img')
        sudo 'sed -i -r "/(.*)swap(.*)swap(.*)/d" /etc/fstab'
        sudo 'swapoff -a'
      end

      unless test "[ -f /etc/docker/daemon.json ]"
        # Check /var/lib/kubelet/config.yaml cgroupDriver
        daemon_json = StringIO.new <<~JSON
        {
          "exec-opts": ["native.cgroupdriver=systemd"]
        }
        JSON
        upload! daemon_json, '/tmp/daemon.json'
        sudo 'mkdir /etc/docker' unless test "[ -d /etc/docker ]"
        execute 'cat /tmp/daemon.json | sudo tee /etc/docker/daemon.json > /dev/null'
        sudo :systemctl, 'restart docker'
      end

      docker_images = capture('docker images')
      unless docker_images.include?('k8s.gcr.io/pause')
        # kubeadm config images list
        images = %w{
          k8s.gcr.io/kube-apiserver:v1.23.1
          k8s.gcr.io/kube-controller-manager:v1.23.1
          k8s.gcr.io/kube-scheduler:v1.23.1
          k8s.gcr.io/kube-proxy:v1.23.1
          k8s.gcr.io/pause:3.6
          k8s.gcr.io/etcd:3.5.1-0
          k8s.gcr.io/coredns/coredns:v1.8.6
        }
        images.each do |image|
          if image.include?('coredns')
            mirror_image = image.sub('k8s.gcr.io/coredns', 'registry.cn-hangzhou.aliyuncs.com/google_containers')
          else
            mirror_image = image.sub('k8s.gcr.io', 'registry.cn-hangzhou.aliyuncs.com/google_containers')
          end
          execute :docker, "pull #{mirror_image}"
          execute :docker, "tag #{mirror_image} #{image}"
        end
      end

      if role == 'master'
        unless test "[ -f $HOME/.kube/config ]"
          sudo :kubeadm, 'reset --force'
          sudo :kubeadm, 'init --pod-network-cidr 10.244.0.0/16'

          execute :mkdir, '-p $HOME/.kube'
          sudo :cp, '/etc/kubernetes/admin.conf $HOME/.kube/config'
          sudo :chown, '$(id -u):$(id -g) $HOME/.kube/config'

          # Installing a Pod network add-on
          execute :kubectl, 'apply -f https://docs.projectcalico.org/manifests/calico.yaml'
          execute :kubectl, 'set env daemonset/calico-node -n kube-system CALICO_IPV4POOL_CIDR="10.244.0.0/16"'
          execute :kubectl, 'set env daemonset/calico-node -n kube-system IP_AUTODETECTION_METHOD=interface="(eth0|enp1s0|ens33|ens18)"'
        end
      elsif role == 'worker'

      else
        puts "Unknown Role #{role}."
      end
    end
  end

  # https://microk8s.io/
  desc 'microk8s ubuntu-desktop deploy', 'install microk8s for ubuntu-desktop'
  option :channel, :default => 'latest/stable'
  def microk8s(hostname, user='deploy')
    channel = options[:channel]
    on "#{user}@#{hostname}", in: :sequence, wait: 5 do
      sudo :snap, 'refresh'
      # sudo snap info microk8s
      sudo :snap, "install microk8s --classic --channel=#{channel}"

      images = capture('microk8s ctr images list')
      unless images.include?('k8s.gcr.io/pause:3.1')
        execute :microk8s, 'ctr images pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1'
        execute :microk8s, 'ctr images tag registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 k8s.gcr.io/pause:3.1'
      end

      unless images.include?('k8s.gcr.io/metrics-server/metrics-server:v0.5.2')
        execute :microk8s, 'ctr images pull registry.cn-hangzhou.aliyuncs.com/google_containers/metrics-server:v0.5.2'
        execute :microk8s, 'ctr images tag registry.cn-hangzhou.aliyuncs.com/google_containers/metrics-server:v0.5.2 k8s.gcr.io/metrics-server/metrics-server:v0.5.2'
      end

      bashrc = capture('cat ~/.bashrc')
      unless bashrc.include?('alias kubectl')
        execute <<~BASH
          echo "alias kubectl='microk8s.kubectl'" | tee -a ~/.bashrc
        BASH
      end

      sudo :usermod, "-a -G microk8s #{user}"
      sudo :chown, "-f -R #{user} ~/.kube" if test "[ -d /home/#{user}/.kube ]"

      # reboot
      # microk8s enable dashboard dns registry istio
      # microk8s status
    end
  end

  private
    def generate(template, locals={})
      context = new_binding(locals)
      CapturableERB.new(template, nil, "-", "@output_buffer").result(context)
    end
    
    def new_binding(locals)
      binding.tap do |b|
        locals.each do |name, value|
          b.local_variable_set(name, value)
        end
      end
    end

end

Awesome.start(ARGV)